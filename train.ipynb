{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6718,
     "status": "ok",
     "timestamp": 1681494125235,
     "user": {
      "displayName": "Capstone_MusicAIn",
      "userId": "06857692388250594938"
     },
     "user_tz": -330
    },
    "id": "U7eYTRvdfCeU",
    "outputId": "011fb5b5-f999-4cde-f297-43b67b4944c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from pre_processing.ipynb\n",
      "GPU is installed and available\n",
      "Sun Apr 16 11:00:54 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.41                 Driver Version: 531.41       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 T...  WDDM | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P0               19W /  N/A|    405MiB /  4096MiB |      8%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      9792      C   ...win\\anaconda3\\envs\\tfgpu\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     29764      C   ...win\\anaconda3\\envs\\tfgpu\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import import_ipynb\n",
    "import pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681494130316,
     "user": {
      "displayName": "Capstone_MusicAIn",
      "userId": "06857692388250594938"
     },
     "user_tz": -330
    },
    "id": "xnbxVhLKbBj8"
   },
   "outputs": [],
   "source": [
    "import keras as keras\n",
    "from pre_processing import generate_training_sequences, SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681494133887,
     "user": {
      "displayName": "Capstone_MusicAIn",
      "userId": "06857692388250594938"
     },
     "user_tz": -330
    },
    "id": "Dwjs4geibTXK"
   },
   "outputs": [],
   "source": [
    "OUTPUT_UNITS = 38\n",
    "NUM_UNITS = [256,128,64]\n",
    "LOSS = \"sparse_categorical_crossentropy\"\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "SAVE_MODEL_PATH = r\"C:/Users/aswin/Downloads/Capstone - SP/Weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1681494137330,
     "user": {
      "displayName": "Capstone_MusicAIn",
      "userId": "06857692388250594938"
     },
     "user_tz": -330
    },
    "id": "cZqluRSIbTcP"
   },
   "outputs": [],
   "source": [
    "def build_model(output_units, num_units, loss, learning_rate):\n",
    "    input = keras.layers.Input(shape=(None, output_units))\n",
    "    x = keras.layers.LSTM(num_units[0], return_sequences=True)(input)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.LSTM(num_units[1], return_sequences=True)(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.LSTM(num_units[2])(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    output = keras.layers.Dense(output_units, activation=\"softmax\")(x)\n",
    "    model = keras.Model(input, output)\n",
    "    model.compile(loss=loss,optimizer=keras.optimizers.Adam(learning_rate=learning_rate),metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1681494144554,
     "user": {
      "displayName": "Capstone_MusicAIn",
      "userId": "06857692388250594938"
     },
     "user_tz": -330
    },
    "id": "Ym-pkfEkDdlQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15522364,
     "status": "ok",
     "timestamp": 1681509672183,
     "user": {
      "displayName": "Capstone_MusicAIn",
      "userId": "06857692388250594938"
     },
     "user_tz": -330
    },
    "id": "w6VM6hSobTew",
    "outputId": "39863482-6e12-4cf6-f836-f8aafaa26711",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 362178 sequences.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 38)]        0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 256)         302080    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 256)         0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 128)         197120    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 38)                2470      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 551,078\n",
      "Trainable params: 551,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 48\u001b[0m\n\u001b[0;32m     44\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(SAVE_MODEL_PATH)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(output_units, num_units, loss, learning_rate)\u001b[0m\n\u001b[0;32m     37\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [checkpoint]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# save the model\u001b[39;00m\n\u001b[0;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39msave(SAVE_MODEL_PATH)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "def train(output_units=OUTPUT_UNITS, num_units=NUM_UNITS, loss=LOSS, learning_rate=LEARNING_RATE):\n",
    "    \"\"\"Train and save TF model.\n",
    "\n",
    "    :param output_units (int): Num output units\n",
    "    :param num_units (list of int): Num of units in hidden layers\n",
    "    :param loss (str): Type of loss function to use\n",
    "    :param learning_rate (float): Learning rate to apply\n",
    "    \"\"\"\n",
    "\n",
    "    # generate the training sequences\n",
    "    inputs, targets = generate_training_sequences(SEQUENCE_LENGTH)\n",
    "\n",
    "    # build the network\n",
    "    model = build_model(output_units, num_units, loss, learning_rate)\n",
    "\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    # Mount Google Drive\n",
    "    #drive.mount('/content/drive')\n",
    "\n",
    "    # Create a folder to save the weights\n",
    "    if not os.path.exists('C:/Users/aswin/Downloads/Capstone - SP/Weights'):\n",
    "        os.makedirs('C:/Users/aswin/Downloads/Capstone - SP/Weights')\n",
    "\n",
    "    # Define the file path for the weights\n",
    "    filepath = \"C:/Users/aswin/Downloads/Capstone - SP/Weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "\n",
    "    # Create a ModelCheckpoint callback to save weights\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    # Define the list of callbacks to be used during training\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "    # train the model\n",
    "    model.fit(inputs, targets, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks_list)\n",
    "\n",
    "    # save the model\n",
    "    model.save(SAVE_MODEL_PATH)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
